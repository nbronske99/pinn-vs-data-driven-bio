{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": []},
    "kernelspec": {"name": "python3", "display_name": "Python 3"}
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05 — Side-by-Side Comparison\n",
        "\n",
        "Loads saved metrics from notebooks 02–04 and produces:\n",
        "1. Overlay plot of both models' predictions vs. ground truth  \n",
        "2. Quantitative metrics table (MSE, MAE, max error) on train and test sets  \n",
        "3. Training dynamics comparison  \n",
        "4. Sparse-data ablation summary\n",
        "\n",
        "**Run notebooks 02, 03, and 04 first.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ==================== LOAD EVERYTHING ====================\n",
        "data = np.load('data/synthetic_m.npz')\n",
        "t = data['t']\n",
        "V = data['V']\n",
        "m_true = data['m_true']\n",
        "\n",
        "dd = np.load('outputs/02_metrics.npz')\n",
        "pinn = np.load('outputs/03_metrics.npz')\n",
        "\n",
        "dd_pred   = dd['m_pred_full']\n",
        "pinn_pred = pinn['m_pred_full']\n",
        "train_idx = dd['train_idx']\n",
        "test_idx  = dd['test_idx']\n",
        "\n",
        "print('All data loaded successfully.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== QUANTITATIVE METRICS ====================\n",
        "def compute_metrics(y_true, y_pred, idx):\n",
        "    err = y_true[idx] - y_pred[idx]\n",
        "    return {\n",
        "        'MSE': np.mean(err ** 2),\n",
        "        'MAE': np.mean(np.abs(err)),\n",
        "        'Max Error': np.max(np.abs(err)),\n",
        "        'RMSE': np.sqrt(np.mean(err ** 2))\n",
        "    }\n",
        "\n",
        "dd_train   = compute_metrics(m_true, dd_pred, train_idx)\n",
        "dd_test    = compute_metrics(m_true, dd_pred, test_idx)\n",
        "pinn_train = compute_metrics(m_true, pinn_pred, train_idx)\n",
        "pinn_test  = compute_metrics(m_true, pinn_pred, test_idx)\n",
        "\n",
        "print(f'{\"\":>14s}  {\"DD Train\":>12s}  {\"DD Test\":>12s}  {\"PINN Train\":>12s}  {\"PINN Test\":>12s}')\n",
        "print('-' * 70)\n",
        "for metric in ['MSE', 'MAE', 'RMSE', 'Max Error']:\n",
        "    print(f'{metric:>14s}  {dd_train[metric]:>12.6f}  {dd_test[metric]:>12.6f}  {pinn_train[metric]:>12.6f}  {pinn_test[metric]:>12.6f}')\n",
        "\n",
        "# Improvement\n",
        "if dd_test['MSE'] > 0:\n",
        "    pct = (dd_test['MSE'] - pinn_test['MSE']) / dd_test['MSE'] * 100\n",
        "    print(f'\\nPINN test MSE improvement over data-driven: {pct:+.1f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== OVERLAY PREDICTION PLOT ====================\n",
        "fig, axs = plt.subplots(3, 1, figsize=(12, 10))\n",
        "\n",
        "# Voltage protocol\n",
        "axs[0].plot(t, V, 'b-', lw=1.5)\n",
        "axs[0].set_ylabel('Voltage (mV)', fontsize=12)\n",
        "axs[0].set_title('Voltage Step Protocol', fontsize=13)\n",
        "axs[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Both predictions overlaid\n",
        "axs[1].plot(t, m_true, 'k-', label='Ground Truth', lw=2.5, alpha=0.8)\n",
        "axs[1].plot(t, dd_pred, '--', color='#e74c3c', label='Data-Driven (ReLU)', lw=2)\n",
        "axs[1].plot(t, pinn_pred, '--', color='#2ecc71', label='PINN (Tanh + ODE)', lw=2)\n",
        "axs[1].scatter(t[test_idx], m_true[test_idx], c='orange', s=6, zorder=5, alpha=0.5, label='Test points')\n",
        "axs[1].set_ylabel('m(t)', fontsize=12)\n",
        "axs[1].set_title('Prediction Comparison', fontsize=13)\n",
        "axs[1].legend(fontsize=11); axs[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Pointwise absolute error\n",
        "axs[2].plot(t, np.abs(m_true - dd_pred), color='#e74c3c', label='Data-Driven |error|', lw=1.5, alpha=0.8)\n",
        "axs[2].plot(t, np.abs(m_true - pinn_pred), color='#2ecc71', label='PINN |error|', lw=1.5, alpha=0.8)\n",
        "axs[2].set_xlabel('Time (ms)', fontsize=12)\n",
        "axs[2].set_ylabel('Absolute Error', fontsize=12)\n",
        "axs[2].set_title('Pointwise Error', fontsize=13)\n",
        "axs[2].legend(fontsize=11); axs[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('PINN vs. Data-Driven: Full Comparison on HH m-gate', fontsize=15, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/05_comparison_overlay.png', dpi=200)\n",
        "plt.show()\n",
        "print('Saved to outputs/05_comparison_overlay.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== TRAINING DYNAMICS ====================\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axs[0].plot(dd['train_losses'], label='DD Train', color='#e74c3c')\n",
        "axs[0].plot(dd['test_losses'], label='DD Test', color='#e74c3c', linestyle='--', alpha=0.7)\n",
        "axs[0].plot(pinn['train_losses'], label='PINN Total', color='#2ecc71')\n",
        "axs[0].plot(pinn['test_losses'], label='PINN Test', color='#2ecc71', linestyle='--', alpha=0.7)\n",
        "axs[0].set_xlabel('Epoch'); axs[0].set_ylabel('Loss')\n",
        "axs[0].set_title('Training Curves')\n",
        "axs[0].set_yscale('log')\n",
        "axs[0].legend(); axs[0].grid(True, alpha=0.3)\n",
        "\n",
        "# PINN loss decomposition\n",
        "axs[1].plot(pinn['data_losses'], label='Data Loss', color='#3498db')\n",
        "axs[1].plot(pinn['phys_losses'], label='Physics Loss', color='#9b59b6')\n",
        "axs[1].plot(pinn['train_losses'], label='Total Loss', color='#2ecc71', lw=2)\n",
        "axs[1].set_xlabel('Epoch'); axs[1].set_ylabel('Loss')\n",
        "axs[1].set_title('PINN Loss Decomposition')\n",
        "axs[1].set_yscale('log')\n",
        "axs[1].legend(); axs[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/05_training_dynamics.png', dpi=200)\n",
        "plt.show()\n",
        "print('Saved to outputs/05_training_dynamics.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== ABLATION SUMMARY (if notebook 04 was run) ====================\n",
        "ablation_path = 'outputs/04_ablation_results.npz'\n",
        "if os.path.exists(ablation_path):\n",
        "    ab = np.load(ablation_path)\n",
        "    sizes = ab['train_sizes']\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(9, 6))\n",
        "    ax.errorbar(sizes, ab['dd_means'], yerr=ab['dd_stds'],\n",
        "                marker='o', capsize=5, lw=2, ms=8,\n",
        "                label='Data-Driven (ReLU)', color='#e74c3c')\n",
        "    ax.errorbar(sizes, ab['pinn_means'], yerr=ab['pinn_stds'],\n",
        "                marker='s', capsize=5, lw=2, ms=8,\n",
        "                label='PINN (Tanh + ODE)', color='#2ecc71')\n",
        "\n",
        "    ax.set_xlabel('Training Set Size', fontsize=13)\n",
        "    ax.set_ylabel('Test MSE', fontsize=13)\n",
        "    ax.set_title('Sparse-Data Ablation: Generalization vs. Data Quantity', fontsize=14)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.set_xscale('log'); ax.set_yscale('log')\n",
        "    ax.grid(True, which='both', alpha=0.3)\n",
        "    ax.set_xticks(sizes)\n",
        "    ax.set_xticklabels(sizes)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/05_ablation_summary.png', dpi=200)\n",
        "    plt.show()\n",
        "    \n",
        "    # Print improvement at each size\n",
        "    print(f'{\"N_train\":>8}  {\"DD MSE\":>10}  {\"PINN MSE\":>10}  {\"PINN advantage\":>14}')\n",
        "    print('-' * 48)\n",
        "    for i, n in enumerate(sizes):\n",
        "        improv = (ab['dd_means'][i] - ab['pinn_means'][i]) / ab['dd_means'][i] * 100\n",
        "        print(f'{n:>8d}  {ab[\"dd_means\"][i]:>10.6f}  {ab[\"pinn_means\"][i]:>10.6f}  {improv:>+12.1f}%')\n",
        "else:\n",
        "    print('Notebook 04 results not found — run 04_sparse_ablation.ipynb first.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Key findings to reference in the paper:\n",
        "\n",
        "1. **Full-data regime:** Both models fit the HH m-gate well with 800 training points. The PINN's advantage is modest here.  \n",
        "2. **Sparse-data regime:** As training data decreases, the data-driven model degrades significantly while the PINN remains accurate — the physics constraint acts as a powerful regularizer.  \n",
        "3. **Activation functions matter:** Tanh (smooth, infinitely differentiable) is critical for PINNs. ReLU's piecewise-linear nature kills gradient signal through the physics loss.  \n",
        "4. **Collocation is free:** The PINN evaluates physics at all time points regardless of label availability — it gets extra information from the ODE without needing more labeled data."
      ]
    }
  ]
}
