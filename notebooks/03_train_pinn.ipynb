{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": []},
    "kernelspec": {"name": "python3", "display_name": "Python 3"}
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 — Physics-Informed Neural Network (PINN)\n",
        "\n",
        "Trains a PINN that embeds the Hodgkin-Huxley ODE residual directly into the loss function.  \n",
        "Uses **Tanh** activations (smooth, nonzero higher-order derivatives — critical for autograd-based physics loss).  \n",
        "Same 80/20 train/test split as the baseline for fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==================== LOAD DATA ====================\n",
        "data = np.load('data/synthetic_m.npz')\n",
        "t = data['t']\n",
        "V = data['V']\n",
        "m_true = data['m_true']\n",
        "\n",
        "# ==================== SAME TRAIN / TEST SPLIT ====================\n",
        "split_data = np.load('data/split_indices.npz')\n",
        "train_idx = split_data['train_idx']\n",
        "test_idx  = split_data['test_idx']\n",
        "\n",
        "X_all = np.stack([t, V], axis=1)\n",
        "\n",
        "X_train = torch.tensor(X_all[train_idx], dtype=torch.float32)\n",
        "y_train = torch.tensor(m_true[train_idx], dtype=torch.float32).unsqueeze(1)\n",
        "X_test  = torch.tensor(X_all[test_idx],  dtype=torch.float32)\n",
        "y_test  = torch.tensor(m_true[test_idx],  dtype=torch.float32).unsqueeze(1)\n",
        "X_full  = torch.tensor(X_all, dtype=torch.float32)\n",
        "\n",
        "print(f'Training samples: {len(train_idx)}')\n",
        "print(f'Test samples:     {len(test_idx)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== HH RATE FUNCTIONS (PyTorch) ====================\n",
        "def alpha_m(V):\n",
        "    return 0.1 * (V + 40.0) / (1.0 - torch.exp(-(V + 40.0) / 10.0))\n",
        "\n",
        "def beta_m(V):\n",
        "    return 4.0 * torch.exp(-(V + 65.0) / 18.0)\n",
        "\n",
        "# ==================== PINN MODEL (Tanh activations) ====================\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def physics_residual(self, x):\n",
        "        \"\"\"Compute ODE residual: dm/dt - [alpha(1-m) - beta*m]\"\"\"\n",
        "        x = x.clone().requires_grad_(True)\n",
        "        m_pred = self(x)\n",
        "        dm_dt = torch.autograd.grad(\n",
        "            m_pred, x, grad_outputs=torch.ones_like(m_pred),\n",
        "            create_graph=True\n",
        "        )[0][:, 0:1]  # derivative w.r.t. t (first input column)\n",
        "\n",
        "        V = x[:, 1:2]\n",
        "        residual = dm_dt - (alpha_m(V) * (1 - m_pred) - beta_m(V) * m_pred)\n",
        "        return residual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== TRAINING ====================\n",
        "torch.manual_seed(0)\n",
        "model = PINN()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "lambda_phys = 0.1  # physics loss weight\n",
        "\n",
        "epochs = 3000\n",
        "train_losses = []\n",
        "test_losses  = []\n",
        "data_losses  = []\n",
        "phys_losses  = []\n",
        "\n",
        "# Collocation points: evaluate physics on the FULL time domain\n",
        "# (physics doesn't need labels, just the ODE constraint)\n",
        "X_colloc = X_full.clone()\n",
        "\n",
        "print('Training PINN (physics embedded in loss)...')\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Data loss — only on training points\n",
        "    m_pred_train = model(X_train)\n",
        "    data_loss = criterion(m_pred_train, y_train)\n",
        "\n",
        "    # Physics loss — evaluated on all collocation points\n",
        "    phys_res = model.physics_residual(X_colloc)\n",
        "    phys_loss = torch.mean(phys_res ** 2)\n",
        "\n",
        "    loss = data_loss + lambda_phys * phys_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "    data_losses.append(data_loss.item())\n",
        "    phys_losses.append(phys_loss.item())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_losses.append(criterion(model(X_test), y_test).item())\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f'   Epoch {epoch:4d} | Total: {loss.item():.6f} | Data: {data_loss.item():.6f} | Phys: {phys_loss.item():.6f} | Test: {test_losses[-1]:.6f}')\n",
        "\n",
        "print(f'\\nFinal Total Loss: {train_losses[-1]:.6f}')\n",
        "print(f'Final Data Loss:  {data_losses[-1]:.6f}')\n",
        "print(f'Final Phys Loss:  {phys_losses[-1]:.6f}')\n",
        "print(f'Final Test MSE:   {test_losses[-1]:.6f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== PLOTS ====================\n",
        "m_pred = model(X_full).detach().numpy().flatten()\n",
        "\n",
        "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
        "\n",
        "axs[0].plot(t, V, 'b-', label='Voltage')\n",
        "axs[0].set_ylabel('Voltage (mV)')\n",
        "axs[0].legend(); axs[0].grid(True)\n",
        "\n",
        "axs[1].plot(t, m_true, 'r-', label='True m(t)', lw=2)\n",
        "axs[1].plot(t, m_pred, 'g--', label='PINN prediction', lw=2)\n",
        "axs[1].scatter(t[test_idx], m_true[test_idx], c='orange', s=8, zorder=5, label='Test points')\n",
        "axs[1].set_ylabel('Gating variable m(t)')\n",
        "axs[1].legend(); axs[1].grid(True)\n",
        "\n",
        "axs[2].plot(train_losses, label='Total Loss')\n",
        "axs[2].plot(data_losses, label='Data Loss')\n",
        "axs[2].plot(phys_losses, label='Physics Loss')\n",
        "axs[2].plot(test_losses, label='Test Loss', alpha=0.7)\n",
        "axs[2].set_xlabel('Epoch'); axs[2].set_ylabel('Loss')\n",
        "axs[2].legend(); axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Physics-Informed Neural Network — Tanh activations, ODE constraint')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/03_pinn_results.png', dpi=200)\n",
        "plt.show()\n",
        "print('Plot saved to outputs/03_pinn_results.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ==================== SAVE MODEL + METRICS ====================\n",
        "torch.save(model.state_dict(), 'outputs/03_pinn_weights.pt')\n",
        "\n",
        "np.savez('outputs/03_metrics.npz',\n",
        "         train_losses=np.array(train_losses),\n",
        "         test_losses=np.array(test_losses),\n",
        "         data_losses=np.array(data_losses),\n",
        "         phys_losses=np.array(phys_losses),\n",
        "         m_pred_full=m_pred,\n",
        "         train_idx=train_idx,\n",
        "         test_idx=test_idx)\n",
        "print('Model weights and metrics saved.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
